{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fd123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from genexp.models import DiffusionModel\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "\n",
    "from genexp.sampling import VPSDE, EulerMaruyamaSampler\n",
    "from genexp.trainers.genexp import FDCTrainerFlow\n",
    "from genexp.utils import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67da5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningDiffusion(LightningModule):\n",
    "    def __init__(self, model: DiffusionModel):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    \n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.model(*args, **kwargs)\n",
    "    \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x0, = batch\n",
    "        t = torch.rand(x0.shape[0]).to(x0.device)\n",
    "        alpha, sig = self.model.sde.get_alpha_sigma(t[:, None])\n",
    "        eps = torch.randn(x0.shape).to(x0.device)\n",
    "\n",
    "        xt = torch.sqrt(alpha) * x0 + sig * eps\n",
    "\n",
    "        eps_pred = self(xt, t[:, None])\n",
    "\n",
    "        loss = torch.mean((eps - eps_pred)**2) / 2.\n",
    "        self.log('loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e8345c",
   "metadata": {},
   "source": [
    "## Training base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.randn((50000, 2))\n",
    "x1 = torch.randn((5000, 2)) * 0.3 + 3\n",
    "dataset = torch.vstack((x0, x1))\n",
    "\n",
    "network = nn.Sequential(\n",
    "    nn.Linear(3, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 2)\n",
    ")\n",
    "\n",
    "sde = VPSDE(0.1, 12)\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = DiffusionModel(network, sde).to(device)\n",
    "pl_model = LightningDiffusion(model)\n",
    "\n",
    "\n",
    "dl = DataLoader(TensorDataset(dataset), batch_size=128, shuffle=True)\n",
    "\n",
    "trainer = Trainer(max_epochs=10)\n",
    "trainer.fit(pl_model, dl)\n",
    "torch.save(model.model.state_dict(), 'gauss_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6196becc",
   "metadata": {},
   "source": [
    "## Loading base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b104d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = nn.Sequential(\n",
    "    nn.Linear(3, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 2)\n",
    ")\n",
    "\n",
    "sde = VPSDE(0.1, 12)\n",
    "\n",
    "model = DiffusionModel(network, sde)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.model.load_state_dict(torch.load('../models/gauss_model.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfad164",
   "metadata": {},
   "source": [
    "## Visualizing Pre-trained Density "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = EulerMaruyamaSampler(model.to(device), data_shape=(2,), device=device)\n",
    "\n",
    "samples = []\n",
    "batch_size = 256\n",
    "num_samples = 10000\n",
    "for i in tqdm(range(num_samples // batch_size + 1)):\n",
    "    trajs, ts = sampler.sample_trajectories(N=batch_size, T=1000, device=device)\n",
    "    samples.append(trajs[-1].full.detach().cpu())\n",
    "\n",
    "samples = torch.vstack(samples)[:num_samples]\n",
    "\n",
    "x0 = torch.randn((50000, 2))\n",
    "x1 = torch.randn((5000, 2)) * 0.3 + 3\n",
    "dataset = torch.vstack((x0, x1))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "ax[0].hist(dataset[:, 0], bins=150)\n",
    "ax[1].hist(samples[:, 0].detach().cpu(), bins=150)\n",
    "ax[0].set_title('Data density')\n",
    "ax[1].set_title('Pre-trained model density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7043396",
   "metadata": {},
   "source": [
    "## Fine-tuning with FDC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec5aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import copy\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "config = OmegaConf.load('../configs/example_fdc.yaml')\n",
    "sampler = EulerMaruyamaSampler(model, data_shape=(2,), device=device)\n",
    "model = model.to(device)\n",
    "\n",
    "seed_everything(config.seed)\n",
    "fdc_trainer = FDCTrainerFlow(config, copy.deepcopy(model), copy.deepcopy(model), device=device, sampler=sampler)\n",
    "\n",
    "for k in tqdm(range(config.num_md_iterations)):\n",
    "    for i in range(config.adjoint_matching.num_iterations):\n",
    "        am_dataset = fdc_trainer.generate_dataset()\n",
    "        fdc_trainer.finetune(am_dataset, steps=config.adjoint_matching.finetune_steps)\n",
    "\n",
    "    fdc_trainer.update_base_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173d7e2",
   "metadata": {},
   "source": [
    "## Visualizing Fine-tuned Model's Density "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd6c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = EulerMaruyamaSampler(fdc_trainer.fine_model.to(device), data_shape=(2,), device=device)\n",
    "\n",
    "samples_fdc = []\n",
    "for i in tqdm(range(num_samples // batch_size + 1)):\n",
    "    trajs, ts = sampler.sample_trajectories(N=batch_size, T=1000, device=device)\n",
    "    samples_fdc.append(trajs[-1].full.detach().cpu())\n",
    "\n",
    "samples_fdc = torch.vstack(samples_fdc)[:num_samples]\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 4))\n",
    "ax[0].hist(dataset[:, 0], bins=150)\n",
    "ax[1].hist(samples[:, 0].detach().cpu(), bins=100)\n",
    "ax[2].hist(samples_fdc[:, 0].detach().cpu(), bins=100)\n",
    "ax[0].set_title('Data density')\n",
    "ax[1].set_title('Pre-trained model density')\n",
    "ax[2].set_title('Fine-tuned model density')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genexp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
